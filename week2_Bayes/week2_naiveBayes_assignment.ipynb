{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/anrui/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/anrui/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import process_tweet, lookup\n",
    "import pdb\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from os import getcwd\n",
    "import w2_unittest\n",
    "\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = f\"{getcwd()}/../tmp2/\"\n",
    "nltk.data.path.append(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sets of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "# split the data into two pieces, one for training and one for testing (validation set)\n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg\n",
    "test_x = test_pos + test_neg\n",
    "\n",
    "# avoid assumptions about the length of all_positive_tweets\n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1-1'></a>\n",
    "### 1.1 - Implementing your Helper Functions\n",
    "\n",
    "To help you train your naive bayes model, you will need to compute a dictionary where the keys are a tuple (word, label) and the values are the corresponding frequency.  Note that the labels we'll use here are 1 for positive and 0 for negative.\n",
    "\n",
    "You will also implement a lookup helper function that takes in the `freqs` dictionary, a word, and a label (1 or 0) and returns the number of times that word and label tuple appears in the collection of tweets.\n",
    "\n",
    "For example: given a list of tweets `[\"i am rather excited\", \"you are rather happy\"]` and the label 1, the function will return a dictionary that contains the following key-value pairs:\n",
    "\n",
    "{\n",
    "    (\"rather\", 1): 2,\n",
    "    (\"happi\", 1) : 1, \n",
    "    (\"excit\", 1) : 1\n",
    "}\n",
    "\n",
    "- Notice how for each word in the given string, the same label 1 is assigned to each word.\n",
    "- Notice how the words \"i\" and \"am\" are not saved, since it was removed by process_tweet because it is a stopword.\n",
    "- Notice how the word \"rather\" appears twice in the list of tweets, and so its count value is 2.\n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Exercise 1 - count_tweets\n",
    "Create a function `count_tweets` that takes a list of tweets as input, cleans all of them, and returns a dictionary.\n",
    "- The key in the dictionary is a tuple containing the stemmed word and its class label, e.g. (\"happi\",1).\n",
    "- The value the number of times this word appears in the given collection of tweets (an integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1 GRADED FUNCTION: count_tweets\n",
    "\n",
    "def count_tweets(result, tweets, ys):\n",
    "    '''\n",
    "    Input:\n",
    "        result: a dictionary that will be used to map each pair to its frequency\n",
    "        tweets: a list of tweets\n",
    "        ys: a list corresponding to the sentiment of each tweet (either 0 or 1)\n",
    "    Output:\n",
    "        result: a dictionary mapping each pair to its frequency\n",
    "    '''\n",
    "    ### START CODE HERE ###\n",
    "    # result= {}\n",
    "    for y, tweet in zip(ys, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            # define the key, which is the word and label tuple\n",
    "            pair = (word, y)\n",
    "            \n",
    "            \n",
    "            # if the key exists in the dictionary, increment the count\n",
    "            if pair in result:\n",
    "                result[pair] += 1\n",
    "\n",
    "            # else, if the key is new, add it to the dictionary and set the count to 1\n",
    "            else:\n",
    "                result[pair] = 1\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('happi', 1): 1, ('trick', 0): 1, ('sad', 0): 1, ('tire', 0): 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing your function\n",
    "\n",
    "result = {}\n",
    "tweets = ['i am happy', 'i am tricked', 'i am sad', 'i am tired', 'i am tired']\n",
    "ys = [1, 0, 0, 0, 0]\n",
    "count_tweets(result, tweets, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: {('happi', 1): 1, ('trick', 0): 1, ('sad', 0): 1, ('tire', 0): 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "w2_unittest.test_count_tweets(count_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Train your Model using Naive Bayes\n",
    "\n",
    "Naive bayes is an algorithm that could be used for sentiment analysis. It takes a short time to train and also has a short prediction time.\n",
    "\n",
    "#### So how do you train a Naive Bayes classifier?\n",
    "- The first part of training a naive bayes classifier is to identify the number of classes that you have.\n",
    "- You will create a probability for each class.\n",
    "$P(D_{pos})$ is the probability that the document is positive.\n",
    "$P(D_{neg})$ is the probability that the document is negative.\n",
    "Use the formulas as follows and store the values in a dictionary:\n",
    "\n",
    "$$P(D_{pos}) = \\frac{D_{pos}}{D}\\tag{1}$$\n",
    "\n",
    "$$P(D_{neg}) = \\frac{D_{neg}}{D}\\tag{2}$$\n",
    "\n",
    "Where $D$ is the total number of documents, or tweets in this case, $D_{pos}$ is the total number of positive tweets and $D_{neg}$ is the total number of negative tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior and Logprior\n",
    "\n",
    "The prior probability represents the underlying probability in the target population that a tweet is positive versus negative.  In other words, if we had no specific information and blindly picked a tweet out of the population set, what is the probability that it will be positive versus that it will be negative? That is the \"prior\".\n",
    "\n",
    "The prior is the ratio of the probabilities $\\frac{P(D_{pos})}{P(D_{neg})}$.\n",
    "We can take the log of the prior to rescale it, and we'll call this the logprior\n",
    "\n",
    "$$\\text{logprior} = log \\left( \\frac{P(D_{pos})}{P(D_{neg})} \\right) = log \\left( \\frac{D_{pos}}{D_{neg}} \\right)$$.\n",
    "\n",
    "Note that $log(\\frac{A}{B})$ is the same as $log(A) - log(B)$.  So the logprior can also be calculated as the difference between two logs:\n",
    "\n",
    "$$\\text{logprior} = \\log (P(D_{pos})) - \\log (P(D_{neg})) = \\log (D_{pos}) - \\log (D_{neg})\\tag{3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the freqs dictionary for later uses\n",
    "freqs = count_tweets({}, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('followfriday', 1.0), ('top', 1.0), ('engag', 1.0), ('member', 1.0)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(freqs.keys())[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs[('followfriday', 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('followfriday', 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/anrui/Desktop/projects/8 NLP learning/NLP_learning/week2_Bayes/week2_naiveBayes_assignment.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anrui/Desktop/projects/8%20NLP%20learning/NLP_learning/week2_Bayes/week2_naiveBayes_assignment.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m freqs[(\u001b[39m'\u001b[39;49m\u001b[39mfollowfriday\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m0\u001b[39;49m)]\n",
      "\u001b[0;31mKeyError\u001b[0m: ('followfriday', 0)"
     ]
    }
   ],
   "source": [
    "freqs[('followfriday', 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['followfriday',\n",
       " 'top',\n",
       " 'engag',\n",
       " 'member',\n",
       " 'commun',\n",
       " 'week',\n",
       " ':)',\n",
       " 'hey',\n",
       " 'jame',\n",
       " 'odd',\n",
       " ':/',\n",
       " 'pleas',\n",
       " 'call',\n",
       " 'contact',\n",
       " 'centr',\n",
       " '02392441234',\n",
       " 'abl',\n",
       " 'assist',\n",
       " 'mani',\n",
       " 'thank',\n",
       " 'listen',\n",
       " 'last',\n",
       " 'night',\n",
       " 'bleed',\n",
       " 'amaz',\n",
       " 'track',\n",
       " 'scotland',\n",
       " 'congrat',\n",
       " 'yeaaah',\n",
       " 'yipppi',\n",
       " 'accnt',\n",
       " 'verifi',\n",
       " 'rqst',\n",
       " 'succeed',\n",
       " 'got',\n",
       " 'blue',\n",
       " 'tick',\n",
       " 'mark',\n",
       " 'fb',\n",
       " 'profil',\n",
       " '15',\n",
       " 'day',\n",
       " 'one',\n",
       " 'irresist',\n",
       " 'flipkartfashionfriday',\n",
       " 'like',\n",
       " 'keep',\n",
       " 'love',\n",
       " 'custom',\n",
       " 'wait',\n",
       " 'long',\n",
       " 'hope',\n",
       " 'enjoy',\n",
       " 'happi',\n",
       " 'friday',\n",
       " 'lwwf',\n",
       " 'second',\n",
       " 'thought',\n",
       " '’',\n",
       " 'enough',\n",
       " 'time',\n",
       " 'dd',\n",
       " 'new',\n",
       " 'short',\n",
       " 'enter',\n",
       " 'system',\n",
       " 'sheep',\n",
       " 'must',\n",
       " 'buy',\n",
       " 'jgh',\n",
       " 'go',\n",
       " 'bayan',\n",
       " ':d',\n",
       " 'bye',\n",
       " 'act',\n",
       " 'mischiev',\n",
       " 'etl',\n",
       " 'layer',\n",
       " 'in-hous',\n",
       " 'wareh',\n",
       " 'app',\n",
       " 'katamari',\n",
       " 'well',\n",
       " '…',\n",
       " 'name',\n",
       " 'impli',\n",
       " ':p',\n",
       " 'influenc',\n",
       " 'big',\n",
       " '...',\n",
       " 'juici',\n",
       " 'selfi',\n",
       " 'follow',\n",
       " 'u',\n",
       " 'back',\n",
       " 'perfect',\n",
       " 'alreadi',\n",
       " 'know',\n",
       " \"what'\",\n",
       " 'great',\n",
       " 'opportun',\n",
       " 'junior',\n",
       " 'triathlet',\n",
       " 'age',\n",
       " '12',\n",
       " '13',\n",
       " 'gatorad',\n",
       " 'seri',\n",
       " 'get',\n",
       " 'entri',\n",
       " 'lay',\n",
       " 'greet',\n",
       " 'card',\n",
       " 'rang',\n",
       " 'print',\n",
       " 'today',\n",
       " 'job',\n",
       " ':-)',\n",
       " \"friend'\",\n",
       " 'lunch',\n",
       " 'yummm',\n",
       " 'nostalgia',\n",
       " 'tb',\n",
       " 'ku',\n",
       " 'id',\n",
       " 'conflict',\n",
       " 'help',\n",
       " \"here'\",\n",
       " 'screenshot',\n",
       " 'work',\n",
       " 'hi',\n",
       " 'liv',\n",
       " 'hello',\n",
       " 'need',\n",
       " 'someth',\n",
       " 'fm',\n",
       " 'twitter',\n",
       " '—',\n",
       " 'sure',\n",
       " 'thing',\n",
       " 'dm',\n",
       " 'x',\n",
       " \"i'v\",\n",
       " 'heard',\n",
       " 'four',\n",
       " 'season',\n",
       " 'pretti',\n",
       " 'dope',\n",
       " 'penthous',\n",
       " 'obv',\n",
       " 'gobigorgohom',\n",
       " 'fun',\n",
       " \"y'all\",\n",
       " 'yeah',\n",
       " 'suppos',\n",
       " 'lol',\n",
       " 'chat',\n",
       " 'bit',\n",
       " 'youth',\n",
       " '💅🏽',\n",
       " '💋',\n",
       " 'seen',\n",
       " 'year',\n",
       " 'rest',\n",
       " 'goe',\n",
       " 'quickli',\n",
       " 'bed',\n",
       " 'music',\n",
       " 'fix',\n",
       " 'dream',\n",
       " 'spiritu',\n",
       " 'ritual',\n",
       " 'festiv',\n",
       " 'népal',\n",
       " 'begin',\n",
       " 'line-up',\n",
       " 'left',\n",
       " 'see',\n",
       " 'sarah',\n",
       " 'send',\n",
       " 'us',\n",
       " 'email',\n",
       " 'bitsy@bitdefender.com',\n",
       " \"we'll\",\n",
       " 'asap',\n",
       " 'kik',\n",
       " 'hatessuc',\n",
       " '32429',\n",
       " 'kikm',\n",
       " 'lgbt',\n",
       " 'tinder',\n",
       " 'nsfw',\n",
       " 'akua',\n",
       " 'cumshot',\n",
       " 'come',\n",
       " 'hous',\n",
       " 'nsn_supplement',\n",
       " 'effect',\n",
       " 'press',\n",
       " 'releas',\n",
       " 'distribut',\n",
       " 'result',\n",
       " 'link',\n",
       " 'remov',\n",
       " 'pressreleas',\n",
       " 'newsdistribut',\n",
       " 'bam',\n",
       " 'bestfriend',\n",
       " 'lot',\n",
       " 'warsaw',\n",
       " '<3',\n",
       " 'x46',\n",
       " 'everyon',\n",
       " 'watch',\n",
       " 'documentari',\n",
       " 'earthl',\n",
       " 'youtub',\n",
       " 'support',\n",
       " 'buuut',\n",
       " 'oh',\n",
       " 'look',\n",
       " 'forward',\n",
       " 'visit',\n",
       " 'next',\n",
       " 'letsgetmessi',\n",
       " 'jo',\n",
       " 'make',\n",
       " 'feel',\n",
       " 'better',\n",
       " 'never',\n",
       " 'anyon',\n",
       " 'kpop',\n",
       " 'flesh',\n",
       " 'good',\n",
       " 'girl',\n",
       " 'best',\n",
       " 'wish',\n",
       " 'reason',\n",
       " 'epic',\n",
       " 'soundtrack',\n",
       " 'shout',\n",
       " 'ad',\n",
       " 'video',\n",
       " 'playlist',\n",
       " 'im',\n",
       " 'twitch',\n",
       " 'leagu',\n",
       " '1',\n",
       " '4',\n",
       " 'would',\n",
       " 'dear',\n",
       " 'jordan',\n",
       " 'okay',\n",
       " 'fake',\n",
       " 'gameplay',\n",
       " ';)',\n",
       " 'haha',\n",
       " 'kid',\n",
       " 'stuff',\n",
       " 'exactli',\n",
       " 'product',\n",
       " 'line',\n",
       " 'etsi',\n",
       " 'shop',\n",
       " 'check',\n",
       " 'boxroomcraft',\n",
       " 'vacat',\n",
       " 'recharg',\n",
       " 'normal',\n",
       " 'charger',\n",
       " 'asleep',\n",
       " 'talk',\n",
       " 'sooo',\n",
       " 'someon',\n",
       " 'text',\n",
       " 'ye',\n",
       " 'bet',\n",
       " \"he'll\",\n",
       " 'fit',\n",
       " 'hear',\n",
       " 'speech',\n",
       " 'piti',\n",
       " 'green',\n",
       " 'garden',\n",
       " 'midnight',\n",
       " 'sun',\n",
       " 'beauti',\n",
       " 'canal',\n",
       " 'dasvidaniya',\n",
       " 'till',\n",
       " 'scout',\n",
       " 'sg',\n",
       " 'futur',\n",
       " 'wlan',\n",
       " 'pro',\n",
       " 'confer',\n",
       " 'asia',\n",
       " 'chang',\n",
       " 'lollipop',\n",
       " '🍭',\n",
       " 'nez',\n",
       " 'agnezmo',\n",
       " 'oley',\n",
       " 'mama',\n",
       " 'stand',\n",
       " 'stronger',\n",
       " 'god',\n",
       " 'misti',\n",
       " 'babi',\n",
       " 'cute',\n",
       " 'woohoo',\n",
       " \"can't\",\n",
       " 'sign',\n",
       " 'yet',\n",
       " 'still',\n",
       " 'think',\n",
       " 'mka',\n",
       " 'liam',\n",
       " 'access',\n",
       " 'welcom',\n",
       " 'stat',\n",
       " 'arriv',\n",
       " 'unfollow',\n",
       " 'via',\n",
       " 'surpris',\n",
       " 'figur',\n",
       " 'happybirthdayemilybett',\n",
       " 'sweet',\n",
       " 'talent',\n",
       " '2',\n",
       " 'plan',\n",
       " 'drain',\n",
       " 'gotta',\n",
       " 'timezon',\n",
       " 'parent',\n",
       " 'proud',\n",
       " 'least',\n",
       " 'mayb',\n",
       " 'sometim',\n",
       " 'grade',\n",
       " 'al',\n",
       " 'grand',\n",
       " 'manila_bro',\n",
       " 'chosen',\n",
       " 'let',\n",
       " 'around',\n",
       " '..',\n",
       " 'side',\n",
       " 'world',\n",
       " 'eh',\n",
       " 'take',\n",
       " 'care',\n",
       " 'final',\n",
       " 'fuck',\n",
       " 'weekend',\n",
       " 'real',\n",
       " 'x45',\n",
       " 'join',\n",
       " 'hushedcallwithfraydo',\n",
       " 'gift',\n",
       " 'yeahhh',\n",
       " 'hushedpinwithsammi',\n",
       " 'event',\n",
       " 'might',\n",
       " 'luv',\n",
       " 'realli',\n",
       " 'appreci',\n",
       " 'share',\n",
       " 'wow',\n",
       " 'tom',\n",
       " '3',\n",
       " 'gym',\n",
       " 'monday',\n",
       " 'invit',\n",
       " 'scope',\n",
       " 'friend',\n",
       " 'nude',\n",
       " 'sleep',\n",
       " 'birthday',\n",
       " 'want',\n",
       " 't-shirt',\n",
       " 'cool',\n",
       " 'haw',\n",
       " 'phela',\n",
       " 'mom',\n",
       " 'obvious',\n",
       " 'princ',\n",
       " 'charm',\n",
       " 'stage',\n",
       " 'luck',\n",
       " 'tyler',\n",
       " 'hipster',\n",
       " 'glass',\n",
       " 'marti',\n",
       " 'glad',\n",
       " 'done',\n",
       " 'afternoon',\n",
       " 'read',\n",
       " 'kahfi',\n",
       " 'finish',\n",
       " 'ohmyg',\n",
       " 'yaya',\n",
       " 'dub',\n",
       " 'stalk',\n",
       " 'ig',\n",
       " 'gondooo',\n",
       " 'moo',\n",
       " 'tologooo',\n",
       " 'becom',\n",
       " 'detail',\n",
       " 'zzz',\n",
       " 'xx',\n",
       " 'physiotherapi',\n",
       " 'hashtag',\n",
       " '💪',\n",
       " 'monica',\n",
       " 'miss',\n",
       " 'sound',\n",
       " 'morn',\n",
       " \"that'\",\n",
       " 'x43',\n",
       " 'definit',\n",
       " 'tri',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'advic',\n",
       " 'treviso',\n",
       " 'concert',\n",
       " 'citi',\n",
       " 'countri',\n",
       " \"i'll\",\n",
       " 'start',\n",
       " 'fine',\n",
       " 'gorgeou',\n",
       " 'xo',\n",
       " 'oven',\n",
       " 'roast',\n",
       " 'garlic',\n",
       " 'oliv',\n",
       " 'oil',\n",
       " 'dri',\n",
       " 'tomato',\n",
       " 'basil',\n",
       " 'centuri',\n",
       " 'tuna',\n",
       " 'right',\n",
       " 'atchya',\n",
       " 'even',\n",
       " 'almost',\n",
       " 'chanc',\n",
       " 'cheer',\n",
       " 'po',\n",
       " 'ice',\n",
       " 'cream',\n",
       " 'agre',\n",
       " '100',\n",
       " 'heheheh',\n",
       " 'that',\n",
       " 'point',\n",
       " 'stay',\n",
       " 'home',\n",
       " 'soon',\n",
       " 'promis',\n",
       " 'web',\n",
       " 'whatsapp',\n",
       " 'volta',\n",
       " 'funcionar',\n",
       " 'com',\n",
       " 'iphon',\n",
       " 'jailbroken',\n",
       " 'later',\n",
       " '34',\n",
       " 'min',\n",
       " 'leia',\n",
       " 'appear',\n",
       " 'hologram',\n",
       " 'r2d2',\n",
       " 'w',\n",
       " 'messag',\n",
       " 'obi',\n",
       " 'wan',\n",
       " 'sit',\n",
       " 'luke',\n",
       " 'inter',\n",
       " 'ucl',\n",
       " 'arsen',\n",
       " 'small',\n",
       " 'team',\n",
       " 'pass',\n",
       " '🚂',\n",
       " 'dewsburi',\n",
       " 'railway',\n",
       " 'station',\n",
       " 'dew',\n",
       " 'west',\n",
       " 'yorkshir',\n",
       " '430',\n",
       " 'smh',\n",
       " '9:25',\n",
       " 'live',\n",
       " 'strang',\n",
       " 'imagin',\n",
       " 'megan',\n",
       " 'masaantoday',\n",
       " 'a4',\n",
       " 'shweta',\n",
       " 'tripathi',\n",
       " '5',\n",
       " '20',\n",
       " 'kurta',\n",
       " 'half',\n",
       " 'number',\n",
       " 'wsalelov',\n",
       " 'ah',\n",
       " 'larri',\n",
       " 'anyway',\n",
       " 'kinda',\n",
       " 'goood',\n",
       " 'life',\n",
       " 'enn',\n",
       " 'could',\n",
       " 'warmup',\n",
       " '15th',\n",
       " 'bath',\n",
       " 'dum',\n",
       " 'andar',\n",
       " 'ram',\n",
       " 'sampath',\n",
       " 'sona',\n",
       " 'mohapatra',\n",
       " 'samantha',\n",
       " 'edward',\n",
       " 'mein',\n",
       " 'tulan',\n",
       " 'razi',\n",
       " 'wah',\n",
       " 'josh',\n",
       " 'alway',\n",
       " 'smile',\n",
       " 'pictur',\n",
       " '16.20',\n",
       " 'giveitup',\n",
       " 'given',\n",
       " 'ga',\n",
       " 'subsidi',\n",
       " 'initi',\n",
       " 'propos',\n",
       " 'delight',\n",
       " 'yesterday',\n",
       " 'x42',\n",
       " 'lmaoo',\n",
       " 'song',\n",
       " 'ever',\n",
       " 'shall',\n",
       " 'littl',\n",
       " 'throwback',\n",
       " 'outli',\n",
       " 'island',\n",
       " 'cheung',\n",
       " 'chau',\n",
       " 'mui',\n",
       " 'wo',\n",
       " 'total',\n",
       " 'differ',\n",
       " 'kfckitchentour',\n",
       " 'kitchen',\n",
       " 'clean',\n",
       " \"i'm\",\n",
       " 'cusp',\n",
       " 'test',\n",
       " 'water',\n",
       " 'reward',\n",
       " 'arummzz',\n",
       " \"let'\",\n",
       " 'drive',\n",
       " 'travel',\n",
       " 'yogyakarta',\n",
       " 'jeep',\n",
       " 'indonesia',\n",
       " 'instamood',\n",
       " 'wanna',\n",
       " 'skype',\n",
       " 'may',\n",
       " 'nice',\n",
       " 'friendli',\n",
       " 'pretend',\n",
       " 'film',\n",
       " 'congratul',\n",
       " 'winner',\n",
       " 'cheesydelight',\n",
       " 'contest',\n",
       " 'address',\n",
       " 'guy',\n",
       " 'market',\n",
       " '24/7',\n",
       " 'regret',\n",
       " '14',\n",
       " 'hour',\n",
       " 'leav',\n",
       " 'without',\n",
       " 'delay',\n",
       " 'actual',\n",
       " 'easi',\n",
       " 'guess',\n",
       " 'train',\n",
       " 'wd',\n",
       " 'shift',\n",
       " 'engin',\n",
       " 'etc',\n",
       " 'sunburn',\n",
       " 'peel',\n",
       " 'blog',\n",
       " 'huge',\n",
       " 'warm',\n",
       " '☆',\n",
       " 'complet',\n",
       " 'triangl',\n",
       " 'northern',\n",
       " 'ireland',\n",
       " 'sight',\n",
       " 'smthng',\n",
       " 'fr',\n",
       " 'hug',\n",
       " 'xoxo',\n",
       " 'uu',\n",
       " 'jaann',\n",
       " 'topnewfollow',\n",
       " 'connect',\n",
       " 'wonder',\n",
       " 'made',\n",
       " 'fluffi',\n",
       " 'insid',\n",
       " 'pirouett',\n",
       " 'moos',\n",
       " 'trip',\n",
       " 'philli',\n",
       " 'decemb',\n",
       " \"i'd\",\n",
       " 'dude',\n",
       " 'x41',\n",
       " 'question',\n",
       " 'flaw',\n",
       " 'pain',\n",
       " 'negat',\n",
       " 'strength',\n",
       " 'went',\n",
       " 'solo',\n",
       " 'move',\n",
       " 'fav',\n",
       " 'nirvana',\n",
       " 'smell',\n",
       " 'teen',\n",
       " 'spirit',\n",
       " 'rip',\n",
       " 'ami',\n",
       " 'winehous',\n",
       " 'coupl',\n",
       " 'tomhiddleston',\n",
       " 'elizabetholsen',\n",
       " 'yaytheylookgreat',\n",
       " 'goodnight',\n",
       " 'vid',\n",
       " 'wake',\n",
       " 'gonna',\n",
       " 'shoot',\n",
       " 'itti',\n",
       " 'bitti',\n",
       " 'teeni',\n",
       " 'bikini',\n",
       " 'much',\n",
       " '4th',\n",
       " 'togeth',\n",
       " 'end',\n",
       " 'xfile',\n",
       " 'content',\n",
       " 'rain',\n",
       " 'fabul',\n",
       " 'fantast',\n",
       " '♡',\n",
       " 'jb',\n",
       " 'forev',\n",
       " 'belieb',\n",
       " 'nighti',\n",
       " 'bug',\n",
       " 'bite',\n",
       " 'bracelet',\n",
       " 'idea',\n",
       " 'foundri',\n",
       " 'game',\n",
       " 'sens',\n",
       " 'pic',\n",
       " 'ef',\n",
       " 'phone',\n",
       " 'woot',\n",
       " 'derek',\n",
       " 'use',\n",
       " 'parkshar',\n",
       " 'gloucestershir',\n",
       " 'aaaahhh',\n",
       " 'man',\n",
       " 'traffic',\n",
       " 'stress',\n",
       " 'reliev',\n",
       " \"how'r\",\n",
       " 'arbeloa',\n",
       " 'turn',\n",
       " '17',\n",
       " 'omg',\n",
       " 'say',\n",
       " 'europ',\n",
       " 'rise',\n",
       " 'find',\n",
       " 'hard',\n",
       " 'believ',\n",
       " 'uncount',\n",
       " 'coz',\n",
       " 'unlimit',\n",
       " 'cours',\n",
       " 'teamposit',\n",
       " 'aldub',\n",
       " '☕',\n",
       " 'rita',\n",
       " 'info',\n",
       " \"we'd\",\n",
       " 'way',\n",
       " 'boy',\n",
       " 'x40',\n",
       " 'true',\n",
       " 'sethi',\n",
       " 'high',\n",
       " 'exe',\n",
       " 'skeem',\n",
       " 'saam',\n",
       " 'peopl',\n",
       " 'polit',\n",
       " 'izzat',\n",
       " 'wese',\n",
       " 'trust',\n",
       " 'khawateen',\n",
       " 'k',\n",
       " 'sath',\n",
       " 'mana',\n",
       " 'kar',\n",
       " 'deya',\n",
       " 'sort',\n",
       " 'smart',\n",
       " 'hair',\n",
       " 'tbh',\n",
       " 'jacob',\n",
       " 'g',\n",
       " 'upgrad',\n",
       " 'tee',\n",
       " 'famili',\n",
       " 'person',\n",
       " 'two',\n",
       " 'convers',\n",
       " 'onlin',\n",
       " 'mclaren',\n",
       " 'fridayfeel',\n",
       " 'tgif',\n",
       " 'squar',\n",
       " 'enix',\n",
       " 'bissmillah',\n",
       " 'ya',\n",
       " 'allah',\n",
       " \"we'r\",\n",
       " 'socent',\n",
       " 'startup',\n",
       " 'drop',\n",
       " 'your',\n",
       " 'arnd',\n",
       " 'town',\n",
       " 'basic',\n",
       " 'piss',\n",
       " 'cup',\n",
       " 'also',\n",
       " 'terribl',\n",
       " 'complic',\n",
       " 'discuss',\n",
       " 'snapchat',\n",
       " 'lynettelow',\n",
       " 'kikmenow',\n",
       " 'snapm',\n",
       " 'hot',\n",
       " 'amazon',\n",
       " 'kikmeguy',\n",
       " 'defin',\n",
       " 'grow',\n",
       " 'sport',\n",
       " 'rt',\n",
       " 'rakyat',\n",
       " 'write',\n",
       " 'sinc',\n",
       " 'mention',\n",
       " 'fli',\n",
       " 'fish',\n",
       " 'promot',\n",
       " 'post',\n",
       " 'cyber',\n",
       " 'ourdaughtersourprid',\n",
       " 'mypapamyprid',\n",
       " 'papa',\n",
       " 'coach',\n",
       " 'posit',\n",
       " 'kha',\n",
       " 'atleast',\n",
       " 'x39',\n",
       " 'mango',\n",
       " \"lassi'\",\n",
       " \"monty'\",\n",
       " 'marvel',\n",
       " 'though',\n",
       " 'suspect',\n",
       " 'meant',\n",
       " '24',\n",
       " 'hr',\n",
       " 'touch',\n",
       " 'kepler',\n",
       " '452b',\n",
       " 'chalna',\n",
       " 'hai',\n",
       " 'thankyou',\n",
       " 'hazel',\n",
       " 'food',\n",
       " 'brooklyn',\n",
       " 'pta',\n",
       " 'awak',\n",
       " 'okayi',\n",
       " 'awww',\n",
       " 'ha',\n",
       " 'doc',\n",
       " 'splendid',\n",
       " 'spam',\n",
       " 'folder',\n",
       " 'amount',\n",
       " 'nigeria',\n",
       " 'claim',\n",
       " 'rted',\n",
       " 'leg',\n",
       " 'hurt',\n",
       " 'bad',\n",
       " 'mine',\n",
       " 'saturday',\n",
       " 'thaaank',\n",
       " 'puhon',\n",
       " 'happinesss',\n",
       " 'tnc',\n",
       " 'prior',\n",
       " 'notif',\n",
       " 'probabl',\n",
       " 'funni',\n",
       " '2:22',\n",
       " 'fat',\n",
       " 'co',\n",
       " 'ate',\n",
       " 'yuna',\n",
       " 'tamesid',\n",
       " '´',\n",
       " 'googl',\n",
       " 'account',\n",
       " 'scouser',\n",
       " 'everyth',\n",
       " 'zoe',\n",
       " 'mate',\n",
       " 'liter',\n",
       " \"they'r\",\n",
       " 'samee',\n",
       " 'edgar',\n",
       " 'updat',\n",
       " 'log',\n",
       " 'bring',\n",
       " 'abe',\n",
       " 'meet',\n",
       " 'x38',\n",
       " 'sigh',\n",
       " 'dreamili',\n",
       " 'pout',\n",
       " 'eye',\n",
       " 'quacketyquack',\n",
       " 'happen',\n",
       " 'phil',\n",
       " 'em',\n",
       " 'del',\n",
       " 'rodder',\n",
       " 'els',\n",
       " 'play',\n",
       " 'newest',\n",
       " 'gamejam',\n",
       " 'irish',\n",
       " 'literatur',\n",
       " 'inaccess',\n",
       " \"kareena'\",\n",
       " 'fan',\n",
       " 'brain',\n",
       " 'dot',\n",
       " 'braindot',\n",
       " 'fair',\n",
       " 'rush',\n",
       " 'either',\n",
       " 'brandi',\n",
       " '18',\n",
       " 'carniv',\n",
       " 'men',\n",
       " 'put',\n",
       " 'mask',\n",
       " 'xavier',\n",
       " 'forneret',\n",
       " 'jennif',\n",
       " 'site',\n",
       " 'free',\n",
       " '50.000',\n",
       " '8',\n",
       " 'ball',\n",
       " 'pool',\n",
       " 'coin',\n",
       " 'edit',\n",
       " 'trish',\n",
       " '♥',\n",
       " 'grate',\n",
       " 'three',\n",
       " 'comment',\n",
       " 'wakeup',\n",
       " 'besid',\n",
       " 'dirti',\n",
       " 'sex',\n",
       " 'lmaooo',\n",
       " '😤',\n",
       " 'loui',\n",
       " \"he'\",\n",
       " 'throw',\n",
       " 'caus',\n",
       " 'inspir',\n",
       " 'ff',\n",
       " 'twoof',\n",
       " 'gr8',\n",
       " 'wkend',\n",
       " 'kind',\n",
       " 'exhaust',\n",
       " 'word',\n",
       " 'cheltenham',\n",
       " 'area',\n",
       " 'kale',\n",
       " 'crisp',\n",
       " 'ruin',\n",
       " 'x37',\n",
       " 'open',\n",
       " 'worldwid',\n",
       " 'outta',\n",
       " 'sfvbeta',\n",
       " 'vantast',\n",
       " 'xcylin',\n",
       " 'bundl',\n",
       " 'show',\n",
       " 'internet',\n",
       " 'price',\n",
       " 'realisticli',\n",
       " 'pay',\n",
       " 'net',\n",
       " 'educ',\n",
       " 'power',\n",
       " 'weapon',\n",
       " 'nelson',\n",
       " 'mandela',\n",
       " 'recent',\n",
       " 'j',\n",
       " 'chenab',\n",
       " 'flow',\n",
       " 'pakistan',\n",
       " 'incredibleindia',\n",
       " 'teenchoic',\n",
       " 'choiceinternationalartist',\n",
       " 'superjunior',\n",
       " 'caught',\n",
       " 'first',\n",
       " 'salmon',\n",
       " 'super-blend',\n",
       " 'project',\n",
       " 'youth@bipolaruk.org.uk',\n",
       " 'awesom',\n",
       " 'stream',\n",
       " 'artist',\n",
       " 'alma',\n",
       " 'mater',\n",
       " 'highschoolday',\n",
       " 'clientvisit',\n",
       " 'faith',\n",
       " 'christian',\n",
       " 'school',\n",
       " 'lizaminnelli',\n",
       " 'upcom',\n",
       " 'uk',\n",
       " '😄',\n",
       " 'singl',\n",
       " 'hill',\n",
       " 'everi',\n",
       " 'beat',\n",
       " 'wrong',\n",
       " 'readi',\n",
       " 'natur',\n",
       " 'pefumeri',\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k[0] for k in list(freqs.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2 GRADED FUNCTION: train_naive_bayes\n",
    "\n",
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: dictionary from (word, label) to how often the word appears\n",
    "        train_x: a list of tweets\n",
    "        train_y: a list of labels correponding to the tweets (0,1)\n",
    "    Output:\n",
    "        logprior: the log prior. (equation 3 above)\n",
    "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
    "    '''\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # calculate V, the number of unique words in the vocabulary\n",
    "    vocab = [k[0] for k in list(freqs.keys())]\n",
    "    V = len(vocab)  \n",
    "\n",
    "    # calculate N_pos, N_neg, V_pos, V_neg\n",
    "    N_pos = N_neg = 0\n",
    "    for pair in freqs.keys():\n",
    "        # if the label is positive (greater than zero)\n",
    "        if pair[1] > 0:\n",
    "\n",
    "            # Increment the number of positive words by the count for this (word, label) pair\n",
    "            # N_pos += 1 previous calc is wrong\n",
    "            N_pos += freqs[pair]\n",
    "\n",
    "        # else, the label is negative\n",
    "        else:\n",
    "\n",
    "            # increment the number of negative words by the count for this (word,label) pair\n",
    "            N_neg += freqs[pair]\n",
    "    \n",
    "    # Calculate D, the number of documents\n",
    "    D = len(train_y)\n",
    "\n",
    "    # Calculate D_pos, the number of positive documents\n",
    "    D_pos = sum(train_y)\n",
    "\n",
    "    # Calculate D_neg, the number of negative documents\n",
    "    D_neg = D-D_pos\n",
    "\n",
    "    # Calculate logprior\n",
    "    logprior = np.log(D_pos)-np.log(D_neg)\n",
    "    \n",
    "    # For each word in the vocabulary...\n",
    "    for word in vocab:\n",
    "        # get the positive and negative frequency of the word\n",
    "        freq_pos = freqs.get((word, 1),0)\n",
    "        freq_neg = freqs.get((word, 0),0)\n",
    "\n",
    "        # calculate the probability that each word is positive, and negative\n",
    "        p_w_pos = (freq_pos+1)/(N_pos+V)\n",
    "        p_w_neg = (freq_neg+1)/(N_neg+V)\n",
    "\n",
    "        # calculate the log likelihood of the word\n",
    "        loglikelihood[word] = np.log(p_w_pos) - np.log(p_w_neg)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "9161\n"
     ]
    }
   ],
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "logprior, loglikelihood = train_naive_bayes(freqs, train_x, train_y)\n",
    "print(logprior)\n",
    "print(len(loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4 GRADED FUNCTION: naive_bayes_predict\n",
    "\n",
    "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
    "    '''\n",
    "    Input:\n",
    "        tweet: a string\n",
    "        logprior: a number\n",
    "        loglikelihood: a dictionary of words mapping to numbers\n",
    "    Output:\n",
    "        p: the sum of all the logliklihoods of each word in the tweet (if found in the dictionary) + logprior (a number)\n",
    "\n",
    "    '''\n",
    "    ### START CODE HERE ###\n",
    "    # process the tweet to get a list of words\n",
    "    word_l = process_tweet(tweet)\n",
    "\n",
    "    # initialize probability to zero\n",
    "    p = 0\n",
    "\n",
    "    # add the logprior\n",
    "    p += logprior\n",
    "\n",
    "    for word in word_l:\n",
    "\n",
    "        # check if the word exists in the loglikelihood dictionary\n",
    "        if word in loglikelihood:\n",
    "            # add the log likelihood of that word to the probability\n",
    "            p += loglikelihood[word]\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected output is 1.5582894062665407\n"
     ]
    }
   ],
   "source": [
    "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "my_tweet = 'She smiled.'\n",
    "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
    "print('The expected output is', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected output is 1.2084297127404549\n"
     ]
    }
   ],
   "source": [
    "# Experiment with your own tweet.\n",
    "my_tweet = 'i think Aling is my lover, and I dreamed to have sex with her.'\n",
    "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
    "print('The expected output is', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C6 GRADED FUNCTION: test_naive_bayes\n",
    "\n",
    "def test_naive_bayes(test_x, test_y, logprior, loglikelihood, naive_bayes_predict=naive_bayes_predict):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        test_x: A list of tweets\n",
    "        test_y: the corresponding labels for the list of tweets\n",
    "        logprior: the logprior\n",
    "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
    "    Output:\n",
    "        accuracy: (# of tweets classified correctly)/(total # of tweets)\n",
    "    \"\"\"\n",
    "    accuracy = 0  # return this properly\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    y_hats = []\n",
    "    for tweet in test_x:\n",
    "        # if the prediction is > 0\n",
    "        if naive_bayes_predict(tweet, logprior, loglikelihood) > 0:\n",
    "            # the predicted class is 1\n",
    "            y_hat_i = 1\n",
    "        else:\n",
    "            # otherwise the predicted class is 0\n",
    "            y_hat_i = 0\n",
    "\n",
    "        # append the predicted class to the list y_hats\n",
    "        y_hats.append(y_hat_i)\n",
    "\n",
    "    # error is the average of the absolute values of the differences between y_hats and test_y\n",
    "    error = sum([y_hats != test_y])/len(y_hats)\n",
    "\n",
    "    # Accuracy is 1 minus the error\n",
    "    accuracy = 1 - error\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/anrui/Desktop/projects/8 NLP learning/NLP_learning/week2_Bayes/week2_naiveBayes_assignment.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/anrui/Desktop/projects/8%20NLP%20learning/NLP_learning/week2_Bayes/week2_naiveBayes_assignment.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39;49m\u001b[39mNaive Bayes accuracy = \u001b[39;49m\u001b[39m%0.4f\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/anrui/Desktop/projects/8%20NLP%20learning/NLP_learning/week2_Bayes/week2_naiveBayes_assignment.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m       (test_naive_bayes(test_x, test_y, logprior, loglikelihood)))\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes accuracy = %0.4f\" %\n",
    "      (test_naive_bayes(test_x, test_y, logprior, loglikelihood)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C8 GRADED FUNCTION: get_ratio\n",
    "\n",
    "def get_ratio(freqs, word):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: dictionary containing the words\n",
    "\n",
    "    Output: a dictionary with keys 'positive', 'negative', and 'ratio'.\n",
    "        Example: {'positive': 10, 'negative': 20, 'ratio': 0.5}\n",
    "    '''\n",
    "    pos_neg_ratio = {'positive': 0, 'negative': 0, 'ratio': 0.0}\n",
    "    ### START CODE HERE ###\n",
    "    # use lookup() to find positive counts for the word (denoted by the integer 1)\n",
    "    pos_neg_ratio['positive'] = lookup(freqs, word,1)\n",
    "    \n",
    "    # use lookup() to find negative counts for the word (denoted by integer 0)\n",
    "    pos_neg_ratio['negative'] = lookup(freqs, word,0)\n",
    "    \n",
    "    # calculate the ratio of positive to negative counts for the word\n",
    "    pos_neg_ratio['ratio'] = (pos_neg_ratio['positive']+1) / (pos_neg_ratio['negative']+1)\n",
    "    ### END CODE HERE ###\n",
    "    return pos_neg_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
